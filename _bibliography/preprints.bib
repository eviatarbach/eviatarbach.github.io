@misc{vishny_high-dimensional_2024,
  title = {High-Dimensional Covariance Estimation from a Small Number of Samples},
  author = {Vishny, David N. and Morzfeld, Matthias and Gwirtz, Kyle and Bach, Eviatar and Dunbar, Oliver and Hodyss, Daniel},
  year = {2024},
  month = may,
  publisher = {{Earth and Space Science Open Archive}},
  doi = {10.22541/essoar.171501094.44068137/v1},
  archiveprefix = {Earth and Space Science Open Archive},
  abstract = {We synthesize knowledge from numerical weather prediction, inverse theory and statistics to address the problem of estimating a high-dimensional covariance matrix from a small number of samples. This problem is fundamental in statistics, machine learning/artificial intelligence, and in modern Earth science. We create several new adaptive methods for high-dimensional covariance estimation, but one method, which we call NICE (Noise-Informed Covariance Estimation), stands out because it has three important properties: (i) NICE is conceptually simple and computationally efficient; (ii) NICE guarantees symmetric positive semi-definite covariance estimates; and (iii) NICE is largely tuning-free. We illustrate the use of NICE on a large set of Earth-science-inspired numerical examples, including cycling data assimilation, geophysical inversion of field data, and training of feed-forward neural networks with time-averaged data from a chaotic dynamical system. Our theory, heuristics and numerical tests suggest that NICE may indeed be a viable option for high-dimensional covariance estimation in many Earth science problems.}
}

@misc{luk_learning_2024,
  title = {Learning {{Optimal Filters Using Variational Inference}}},
  author = {Luk, Enoch and Bach*, Eviatar and Baptista, Ricardo and Stuart, Andrew},
  year = {2024},
  month = jun,
  number = {arXiv:2406.18066},
  eprint = {2406.18066},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2024-06-27},
  archiveprefix = {arXiv},
  doi = {10.48550/arxiv.2406.18066},
  abstract = {Filtering – the task of estimating the conditional distribution of states of a dynamical system given partial, noisy, observations – is important in many areas of science and engineering, including weather and climate prediction. However, the filtering distribution is generally intractable to obtain for high-dimensional, nonlinear systems. Filters used in practice, such as the ensemble Kalman filter (EnKF), are biased for nonlinear systems and have numerous tuning parameters. Here, we present a framework for learning a parameterized analysis map – the map that takes a forecast distribution and observations to the filtering distribution – using variational inference. We show that this methodology can be used to learn gain matrices for filtering linear and nonlinear dynamical systems, as well as inflation and localization parameters for an EnKF. Future work will apply this framework to learn new filtering algorithms.},
}
